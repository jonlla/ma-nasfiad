from autoencoder_cgp.evolutionary_components.configurations import SearchConfiguration
from autoencoder_cgp.evolutionary_components.logger import ConvModelInfoLogger
from autoencoder_cgp.pipeline import preprocessing as prep, evaluation as eval
from autoencoder_cgp.conv_autoencoder import ConvolutionalAutoencoderEvolSearch
from autoencoder_cgp.evolutionary_components.evolution import initalize_callbacks_test
import os
import pandas as pd
import numpy as np
import argparse
import uuid

parser = argparse.ArgumentParser()
parser.add_argument("--data_path", type=str, required=True,
                    help="Path to preprocessed data in the correct format")
parser.add_argument("--experiments_dir", type=str, required=True,
                    help="Path where generated architectures and results of the evaluation are saved")
parser.add_argument("--db", type=str, required=True,
                    help="Signal-to-Noise Ratio. Selects data from the data_path based on this argument.")
parser.add_argument("--m_type", type=str, required=True,
                    help="Machine Type e.g. valve. Selects data from the data_path based on this argument.")
parser.add_argument("--train_id", type=str, required=True,
                    help="id for the evolutionary architecture search.")
parser.add_argument("--prep_step", type=str, required=True,
                    help="Preprocessing Step. Selects data from the data_path based on this argument.")
parser.add_argument("--warm_start", type=str, required=True,
                    help="If True: Individual of last search is used as a starting point for the next generations. Loads the individual based on parameter experiments_dir")
parser.add_argument("--generations", type=int, required=True,
                    help="Number of generations")
parser.add_argument("--debug", type=str, required=True,
                    help="If enabled only small part of the train and val data is used.")
parser.add_argument("--train_epochs", type=int, required=True,
                    help="Number of training epochs for architectures generated by the search.")
parser.add_argument("--val_epochs", type=int, required=True,
                    help="Number of training epochs for the best found architecture in the evaluation step")
parser.add_argument("--num_evaluations", type=int, required=False, default=1,
                    help="Determines how often the evaluation is repeated.")
parser.add_argument("--evaluate_on", type=str, required=False, default="train",
                    help="Possible values are: \n train - evaluates only on dataset of train_id"
                         + "|| test - evaluates on all datasets except train_id"
                         + "|| all - evaluates on datasets of all ids.")
parser.add_argument("--save_all", type=str, required=False, default="False",
                    help="If True, saves all models that are trained in the evaluation step.")
parser.add_argument("--wandb_api_key", type=str, required=False, default="None",
                    help="Specify an weights & biases api key if you want to log the results of the architecture search.")

parser.add_argument("--verbose", type=str, required=True,
                    help="If True Keras training output as well as model info are printed to the console.")

args = parser.parse_args()

data_path = args.data_path
experiments_dir = args.experiments_dir
db = args.db
m_type = args.m_type
train_id = args.train_id
warm_start = args.warm_start == "True"
generations = args.generations
debug = args.debug == "True"
train_epochs = args.train_epochs
val_epochs = args.val_epochs
verbose = args.verbose == "True"
preprocessing_step = args.prep_step
num_evaluations = args.num_evaluations
evaluate_on = args.evaluate_on
save_all = args.save_all
allowed_eval_params = ["train", "test", "all"]
assert evaluate_on in allowed_eval_params, "Parameter <evaluate_on> should be one of: train, test, all."

df_train_dict, df_test_dict = prep.load_train_test_dict(db, m_type, data_path, preprocessing_step)

all_machine_ids = ["id_00", "id_02", "id_04", "id_06"]
train_machine_id = train_id

INPUT_X = df_train_dict[train_machine_id]["signal_spectrum"][0].shape[0]
INPUT_Y = df_train_dict[train_machine_id]["signal_spectrum"][0].shape[1]
print(f"Input shape: ({INPUT_X}, {INPUT_Y})")

# Select the df_train to train for the model
df_train = df_train_dict[train_machine_id]
df_val = df_test_dict[train_machine_id]

if debug:
    # shrink the train and test for debugging purposes:
    df_train = df_train.iloc[0:50, :]
    df_val = pd.concat([df_val.iloc[0:25, :], df_val.iloc[-25:, :]], axis=0).reset_index(drop=True)

# Convert to (n, dim1, dim2, 1) format
X_train = prep.df_to_neural_network_format(df_train, INPUT_X, INPUT_Y)
X_val = prep.df_to_neural_network_format(df_val, INPUT_X, INPUT_Y)


def evaluate_auc_on_validation_set(model, X_val, df_val):
    X_val_pred = model.predict(X_val)
    return eval.roc_auc(X_val=X_val, X_val_pred=X_val_pred, df_val=df_val)


additional_info = {"input_x": INPUT_X,
                   "input_y": INPUT_Y,
                   "prep_step": preprocessing_step,
                   "train_id": train_machine_id,
                   "db": db,
                   "m_type": m_type,
                   "fitness_measure_name": "AUC"}

if debug:
    wandb_key = None
else:
    if args.wandb_api_key == "None":
        wandb_key = None
    else:
        wandb_key = args.wandb_api_key



batch_size = 16
max_rep_size = INPUT_X * INPUT_Y

search_save_path = f"{experiments_dir}/{m_type}/{db}_{preprocessing_step}/train_{train_id}/"
wandb_project_name = f"{db}db_{m_type}_train_on_{train_id}_{preprocessing_step}"

search_config = SearchConfiguration(epochs=train_epochs, batch_size=batch_size, max_representation_size=max_rep_size)
model_search = ConvolutionalAutoencoderEvolSearch(X_train, fitness_eval_func=evaluate_auc_on_validation_set,
                                                  fitness_func_args={"X_val": X_val, "df_val": df_val},
                                                  maximize_fitness=True, num_generations=generations, num_children=4,
                                                  num_cols=20,
                                                  levelback=5,
                                                  search_config=search_config,
                                                  path=search_save_path,
                                                  warm_start=warm_start,
                                                  wandb_api_key=wandb_key,
                                                  wandb_project_name=wandb_project_name,
                                                  additional_logger_info=additional_info,
                                                  log_keras_train=verbose,
                                                  log_model_info=verbose)
history = model_search.fit()
best_model = model_search.best_model

summary_eval_path = os.path.join(search_save_path, "summary_eval")
if not os.path.exists(summary_eval_path):
    os.makedirs(summary_eval_path)

num_generations = np.max(history["generation"])
# In case the skript is only called for the evaluation and not search for new architectures.
if generations != 0:
    # save model graph
    model_graph_path = os.path.join(summary_eval_path, f"best_architecture_train_on_{train_id}.png")
    eval.save_best_architecture_graph(best_model, path=model_graph_path)
    model_path = os.path.join(summary_eval_path, f"best_model_search_on_{train_id}_train_on{train_id}_from_search.h5")
    best_model.save(model_path)
    # save best model:
    model_search.best_individual.save(summary_eval_path, f"best_individual_search_on_{train_id}.pickle")

    # Final Eval and plot:
    X_val_pred = best_model.predict(X_val)
    plot_path_roc = os.path.join(summary_eval_path, f"roc_search_on_{train_id}_val_on_{train_id}_train_epochs.png")
    eval.plot_roc_auc(X_val, X_val_pred, df_val, plot_path_roc)

    best_auc_search = eval.roc_auc(X_val, X_val_pred, df_val)
    print(f"\n\n Final Fitness is {best_auc_search}")

    # Generation Plot:

    plot_path_gen_fit = os.path.join(summary_eval_path, f"generations_vs_fitness_train_on_{train_id}.png")
    eval.plot_generations_vs_fitness(history, plot_path_gen_fit, fitness_metric="AUC")

    plot_path_gen_best_fit = os.path.join(summary_eval_path, f"generations_vs_best_fitness_train_on_{train_id}.png")
    eval.plot_generations_vs_best_fitness(history, plot_path_gen_best_fit, fitness_metric="AUC")

## ----------------------------------------------------------------------------------------------------
# Create path to save models of the evaluation
model_dir = summary_eval_path + "/eval_models"
if not os.path.exists(model_dir):
    os.makedirs(model_dir)

# Try to load already existing results:
results_path = os.path.join(summary_eval_path, f"results_search_on_{train_id}.csv")
if os.path.exists(results_path):
    df_results_previous = pd.read_csv(results_path, index_col=0)
    if "eval_id" not in df_results_previous.columns:
        df_results_previous["eval_id"] = None
    if "loss" not in df_results_previous.columns:
        df_results_previous["loss"] = None
else:
    df_results_previous = pd.DataFrame(
        columns=["m_type", "db_level", "search_on", "test_on", "AUC", "num_generations", "epochs", "eval_id", "loss"])
    df_results_previous.to_csv(results_path)

# Determine which machine ids shall be tested
if evaluate_on == "train":
    test_machine_ids = [train_machine_id]
elif evaluate_on == "test":
    test_machine_ids = all_machine_ids.copy()
    test_machine_ids.remove(train_machine_id)
elif evaluate_on == "all":
    test_machine_ids = all_machine_ids


for j in range(num_evaluations):

    df_results = pd.DataFrame(
        columns=["m_type", "db_level", "search_on", "test_on", "AUC", "num_generations", "epochs", "eval_id", "loss"])

    for i, test_machine_id in enumerate(test_machine_ids):
        eval_id = uuid.uuid1()
        print("\n\n--------------------------------------------------------------------------\n\n")
        print(f"Evaluating {test_machine_id} in round {j + 1}/{num_evaluations}. Evaluation ID is {eval_id}")
        # define paths to save images
        curve_plot_path = os.path.join(summary_eval_path,
                                       f"trainings_curve_model_search_on_{train_id}_train_on{test_machine_id}.png")
        plot_path_roc = os.path.join(summary_eval_path, f"roc_search_on_{train_id}_val_on_{test_machine_id}.png")
        model_path = os.path.join(model_dir, f"best_model_search_on_{train_id}_train_on{test_machine_id}_eval_{j}.h5")

        INPUT_X = df_train_dict[test_machine_id]["signal_spectrum"][0].shape[0]
        INPUT_Y = df_train_dict[test_machine_id]["signal_spectrum"][0].shape[1]

        # Select the df_train to train for the model
        df_train = df_train_dict[test_machine_id]
        df_val = df_test_dict[test_machine_id]

        if debug:
            # shrink the train and test for debugging purposes:
            df_train = df_train.iloc[0:50, :]
            df_val = pd.concat([df_val.iloc[0:25, :], df_val.iloc[-25:, :]], axis=0).reset_index(drop=True)

        # Convert to (n, dim1, dim2, 1) format
        X_train = prep.df_to_neural_network_format(df_train, INPUT_X, INPUT_Y)
        X_val = prep.df_to_neural_network_format(df_val, INPUT_X, INPUT_Y)


        model = model_search.best_architecture
        model_callbacks = initalize_callbacks_test()
        current_model_history = model.fit(X_train, X_train, batch_size=batch_size, epochs=val_epochs, verbose=2,
                                          callbacks=model_callbacks)

        eval.plot_trainings_curve(current_model_history, curve_plot_path)

        X_val_pred = model.predict(X_val)

        eval.plot_roc_auc(X_val, X_val_pred, df_val, plot_path_roc)
        test_auc = eval.roc_auc(X_val, X_val_pred, df_val)

        if save_all:
            model.save(model_path)

        final_loss = current_model_history.history["loss"][-1]
        df_results.loc[i] = [m_type, db, train_machine_id, test_machine_id, test_auc, num_generations, val_epochs,
                             eval_id, final_loss]

        print(f"\n\n Test Fitness is {test_auc}")

    # Append and save this to the result dataframe:
    df_results_previous = pd.concat([df_results, df_results_previous], axis=0).reset_index(drop=True)

    print(df_results_previous)
    df_results_previous.to_csv(results_path)

if os.path.exists(results_path):
    df_results = pd.read_csv(results_path, index_col=0).drop_duplicates()

df_grouped_data = df_results.groupby(["num_generations", "test_on", "epochs"])["AUC"].agg(
    ["mean", "std", "count"]).reset_index().sort_values(by=["num_generations", "epochs", "test_on"])

print(df_grouped_data)

df_grouped_data.to_csv(os.path.join(summary_eval_path, f"results_search_on_{train_id}_grouped.csv"), index=False)
